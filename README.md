# IADATA700_mangetamain

![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=flat&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=flat&logo=plotly&logoColor=white)
![pytest](https://img.shields.io/badge/pytest-0A9EDC?style=flat&logo=pytest&logoColor=white)
![Tests](https://img.shields.io/badge/tests-144%20passed-success?style=flat)
![PlantUML](https://img.shields.io/badge/PlantUML-Documentation-blue?style=flat)
![Sphinx](https://img.shields.io/badge/Sphinx-Documentation-blue?style=flat&logo=sphinx&logoColor=white)

Dans le cadre d'un enseignement Ã  Telecom Paris, ce projet consiste en une application web interactive d'analyse de donnÃ©es pour une entreprise fictive : **Mangetamain** ; leader dans la recommandation B2C de recettes de cuisine Ã  l'ancienne bio.

## âš¡ DÃ©marrage rapide

```bash
# 1. Installation
uv sync

# 2. PrÃ©traitement (PREMIÃˆRE FOIS UNIQUEMENT)
uv run python -m utils.preprocess_ingredients_matrix

# 3. Lancement de l'application
uv run python run_app.py
```

> ğŸ“¥ **Auto-download intelligent** : Le script vÃ©rifie et tÃ©lÃ©charge automatiquement les donnÃ©es manquantes depuis S3.
> 
> âš¡ **Matrice prÃ©calculÃ©e** : Le preprocessing gÃ©nÃ¨re une matrice de co-occurrence 300x300 pour accÃ©lÃ©rer l'analyse de clustering (~5-10 min, 1 seule fois).

### ğŸ›ï¸ ContrÃ´le de l'application

**DÃ©marrage** :
```bash
python run_app.py          # Lancement avec tÃ©lÃ©chargement auto des donnÃ©es
```

**ArrÃªt** :
- `Ctrl+C` dans le terminal de lancement
- Ou utiliser le script d'arrÃªt : `python stop_app.py`

**Alternative directe** (si les donnÃ©es sont dÃ©jÃ  prÃ©sentes) :
```bash
uv run streamlit run src/app.py
```

## ğŸ“š Documentation

- ğŸ“– **[Documentation complÃ¨te (Sphinx)](docs/build/html/index.html)** - API reference, architecture, guides
- ğŸ—ï¸ **[Diagramme de classes](docs/class-diagram.svg)** - Vue d'ensemble de l'architecture

## ğŸš€ Application Streamlit

### ğŸ“‹ Pages disponibles
1. **ğŸ  Home** - Exploration gÃ©nÃ©rale des donnÃ©es (recettes ou interactions)
2. **ğŸ³ Analyse de clustering des ingrÃ©dients** - Clustering basÃ© sur la co-occurrence
3. **ğŸ”¥ Analyse popularitÃ© des recettes** - PopularitÃ© (nombre d'interactions) vs note moyenne & caractÃ©ristiques (minutes, n_steps, n_ingredients)

### ğŸ› ï¸ Lancement
```bash
uv sync
uv run streamlit run src/app.py
```

### ğŸ“‚ Structure du projet
```
src/
â”œâ”€â”€ app.py                          # Application principale Streamlit
â”œâ”€â”€ core/                          # Modules de base
â”‚   â”œâ”€â”€ data_loader.py            # Chargement des donnÃ©es
â”‚   â”œâ”€â”€ data_explorer.py          # Exploration de base (accÃ¨s aux donnÃ©es)
â”‚   â”œâ”€â”€ interactions_analyzer.py  # AgrÃ©gations popularitÃ© / notes / features
â”‚   â””â”€â”€ ingredients_analyzer.py   # Analyse des ingrÃ©dients
â”œâ”€â”€ components/                   # Composants de l'application
â”‚   â”œâ”€â”€ ingredients_clustering_page.py     # Page clustering des ingrÃ©dients
â”‚   â””â”€â”€ popularity_analysis_page.py         # Page analyse popularitÃ©
â””â”€â”€ utils/                        # Utilitaires (vide actuellement)
```

### ğŸ“Š DonnÃ©es requises
Chemins par dÃ©faut :
- **Recettes** : `data/RAW_recipes.csv`
- **Interactions** : `data/RAW_interactions.csv`

> ğŸ’¡ **PrÃ©requis** : Le fichier de donnÃ©es doit Ãªtre prÃ©sent localement dans le dossier `data/` Ã  la racine du projet.

### âœ¨ FonctionnalitÃ©s
- **Page Home** : Exploration gÃ©nÃ©rale des donnÃ©es + mÃ©triques
- **Clustering IngrÃ©dients** :
  - SÃ©lection du nombre d'ingrÃ©dients Ã  analyser
  - Regroupement normalisÃ© + co-occurrences
  - Clustering K-means + t-SNE
  - Analyse de groupes & debug mappings
- **PopularitÃ© Recettes** :
  - AgrÃ©gat par recette : interaction_count, avg_rating, minutes, n_steps, n_ingredients
  - Scatter Note moyenne vs PopularitÃ©
  - Scatter CaractÃ©ristiques vs PopularitÃ© (taille = note)
  - AperÃ§u DataFrame fusionnÃ© (diagnostic)
  - Filtre sur interactions minimales
  - PrÃ©traitement IQR configurable (exclut les notes pour prÃ©server la distribution rÃ©elle)
  - Segmentation par percentiles (Low â‰¤ P25, Medium â‰¤ P75, High â‰¤ P95, Viral > P95)

### ğŸ”§ PrÃ©traitement & Segmentation

**IQR (InterQuartile Range) Filtering**
- Variables filtrÃ©es: `minutes`, `n_steps`, `n_ingredients`
- Formule: Q1 âˆ’ kÂ·IQR â‰¤ valeur â‰¤ Q3 + kÂ·IQR (k rÃ©glable 1.0 â†’ 20.0)
- `rating` n'est pas filtrÃ© pour conserver les avis extrÃªmes.

**Segmentation PopularitÃ©**
- Low: interaction_count â‰¤ P25
- Medium: P25 < interaction_count â‰¤ P75
- High: P75 < interaction_count â‰¤ P95
- Viral: interaction_count > P95

Cette segmentation reflÃ¨te la distribution longue traÃ®ne et met en Ã©vidence l'extrÃªme raretÃ© des recettes virales.

## ğŸ“ Architecture UML

### ğŸ–¼ï¸ Visualisation directe

![Diagramme UML](docs/class-diagram.svg)

<details>
<summary><b>AperÃ§u (image PNG)</b></summary>

![Architecture UML](docs/class-diagram.png)

> âš ï¸ **Si l'image ne s'affiche pas** : GÃ©nÃ©rez-la avec `plantuml docs/class-diagram.puml`

</details>

**GÃ©nÃ©rer le diagramme :**
```bash
# Installation PlantUML (macOS)
brew install plantuml

# GÃ©nÃ©ration PNG haute rÃ©solution (200 DPI)
plantuml docs/class-diagram.puml

# Ou SVG pour zoom sans perte
plantuml -tsvg docs/class-diagram.puml
```


## ğŸ”„ Preprocessing des donnÃ©es

### Matrice de co-occurrence des ingrÃ©dients

Le projet utilise un preprocessing offline pour optimiser les performances de la page de clustering des ingrÃ©dients.

**ğŸ“ Localisation** : `utils/preprocess_ingredients_matrix.py`

**ğŸ¯ Objectif** :
GÃ©nÃ©rer une matrice de co-occurrence 300Ã—300 prÃ©-calculÃ©e analysant ~230 000 recettes pour identifier les associations frÃ©quentes d'ingrÃ©dients.

**âš™ï¸ Processus** :
1. **Normalisation NLP** : Nettoyage des ingrÃ©dients (lowercase, 50 stop words, regex)
2. **SÃ©lection** : Top 300 ingrÃ©dients par frÃ©quence d'apparition
3. **Construction** : Matrice de co-occurrence symÃ©trique
4. **Export** : Fichiers CSV dans `data/`

**ğŸš€ ExÃ©cution** :
```bash
# PremiÃ¨re installation - gÃ©nÃ©ration requise (5-10 minutes)
uv run python -m utils.preprocess_ingredients_matrix
```

**ğŸ“Š Fichiers gÃ©nÃ©rÃ©s** :
- `data/ingredients_cooccurrence_matrix.csv` (~15-20 MB) : Matrice 300Ã—300
- `data/ingredients_list.csv` (~10 KB) : Liste des 300 ingrÃ©dients avec frÃ©quences

## ğŸ§ª Tests & QualitÃ©

### ExÃ©cuter les tests
```bash
# Tous les tests
uv run pytest

# Tests avec couverture
uv run pytest --cov=src --cov-report=html

# Tests spÃ©cifiques
uv run pytest tests/test_ingredients_clustering_page.py
uv run pytest tests/test_preprocess_ingredients_matrix.py

# Mode verbose
uv run pytest -v
```

### Logger
Le projet utilise un systÃ¨me de logging structurÃ© dans `debug/` :
- **`debug/debug.log`** : Logs INFO/DEBUG dÃ©taillÃ©s
- **`debug/errors.log`** : Erreurs uniquement

Configuration dans `src/core/logger.py` :
```python
from src.core.logger import get_logger
logger = get_logger(__name__)
logger.info("Message d'information")
```

### Cache
SystÃ¨me de cache automatique pour optimiser les analyses lourdes :
- **Localisation** : `cache/analyzer/operation/hash.pkl`
- **ContrÃ´le** : Sidebar de chaque page (activation/nettoyage)
- **DÃ©tection** : Changements de paramÃ¨tres automatiques

