from __future__ import annotations

"""Streamlit page: Analyse de co-occurrence et clustering d'ingrÃ©dients.

Cette page utilise une matrice de co-occurrence PRÃ‰CALCULÃ‰E pour optimiser les performances.
La matrice 300x300 est gÃ©nÃ©rÃ©e Ã  froid par utils/preprocess_ingredients_matrix.py.
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE

from core.logger import get_logger


@dataclass
class IngredientsClusteringConfig:
    """Configuration pour l'analyse de clustering d'ingrÃ©dients.

    Attributes:
        matrix_path: Chemin vers la matrice de co-occurrence prÃ©calculÃ©e.
        ingredients_list_path: Chemin vers la liste des ingrÃ©dients.
        n_ingredients: Nombre d'ingrÃ©dients Ã  analyser (de la matrice 300x300).
        n_clusters: Nombre de clusters Ã  crÃ©er avec K-means.
        tsne_perplexity: ParamÃ¨tre de perplexitÃ© pour la visualisation t-SNE.
    """

    matrix_path: Path = Path("data/ingredients_cooccurrence_matrix.csv")
    ingredients_list_path: Path = Path("data/ingredients_list.csv")
    n_ingredients: int = 40
    n_clusters: int = 4
    tsne_perplexity: int = 30


class IngredientsClusteringPage:
    """Page Streamlit pour l'analyse de clustering des ingrÃ©dients.

    Cette classe charge une matrice de co-occurrence PRÃ‰CALCULÃ‰E et effectue
    le clustering et la visualisation en temps rÃ©el.

    Attributes:
        matrix_path: Chemin vers la matrice de co-occurrence prÃ©calculÃ©e.
        ingredients_list_path: Chemin vers la liste des ingrÃ©dients.
        logger: Instance du logger pour le suivi des opÃ©rations.
    """

    def __init__(
        self,
        matrix_path: str = "data/ingredients_cooccurrence_matrix.csv",
        ingredients_list_path: str = "data/ingredients_list.csv",
    ) -> None:
        """Initialise la page de clustering d'ingrÃ©dients.

        Args:
            matrix_path: Chemin vers la matrice de co-occurrence prÃ©calculÃ©e (300x300).
            ingredients_list_path: Chemin vers la liste des 300 ingrÃ©dients avec frÃ©quences.
        """
        self.matrix_path = Path(matrix_path)
        self.ingredients_list_path = Path(ingredients_list_path)
        self.logger = get_logger()
        self.logger.info("Initializing IngredientsClusteringPage with precomputed matrix")

    @st.cache_data(ttl=None, show_spinner="Chargement de la matrice prÃ©calculÃ©e...")
    def _load_cooccurrence_matrix(_self) -> Optional[tuple[pd.DataFrame, pd.DataFrame]]:
        """Charge et sanitise la matrice de co-occurrence + liste d'ingrÃ©dients.

        Sanitation appliquÃ©e:
        - Strip espaces
        - DÃ©tection mismatch index/colonnes
        - ForÃ§age de la symÃ©trie (colonnes = index) si nÃ©cessaire
        - Suppression doublons Ã©ventuels

        Returns:
            Tuple (matrice 300x300 nettoyÃ©e, liste des ingrÃ©dients) si succÃ¨s, None sinon.
        """
        try:
            if not _self.matrix_path.exists():
                st.error(f"âŒ Matrice introuvable: {_self.matrix_path}")
                st.info("ğŸ’¡ ExÃ©cutez d'abord: `uv run python -m utils.preprocess_ingredients_matrix`")
                st.stop()
                return None

            cooc_matrix = pd.read_csv(_self.matrix_path, index_col=0)
            _self.logger.info(f"âœ… Matrice chargÃ©e brute: {cooc_matrix.shape}")

            # Validation de forme: la matrice doit Ãªtre carrÃ©e et <= 400x400
            if cooc_matrix.shape[0] != cooc_matrix.shape[1] or cooc_matrix.shape[0] < 10:
                _self.logger.error(
                    "âŒ Le fichier chargÃ© n'est pas une matrice de co-occurrence carrÃ©e valide. VÃ©rifiez le chemin fourni."
                )
                st.error(
                    "Le fichier chargÃ© n'est pas une matrice de co-occurrence carrÃ©e. Assurez-vous d'avoir prÃ©calculÃ© la matrice avec `utils/preprocess_ingredients_matrix.py` et que le chemin est `data/ingredients_cooccurrence_matrix.csv`."
                )
                st.stop()
            elif cooc_matrix.shape[0] > 500:
                _self.logger.warning(
                    f"âš ï¸ Matrice trÃ¨s grande ({cooc_matrix.shape}); ce n'est probablement pas le fichier prÃ©calculÃ© attendu."
                )

            # Normalisation lÃ©gÃ¨re des labels (mais on conserve casse/minuscule existante)
            cooc_matrix.index = cooc_matrix.index.str.strip()
            cooc_matrix.columns = cooc_matrix.columns.str.strip()

            # VÃ©rifier symÃ©trie des labels
            idx_set = set(cooc_matrix.index)
            col_set = set(cooc_matrix.columns)
            if idx_set != col_set:
                missing_in_cols = idx_set - col_set
                missing_in_idx = col_set - idx_set
                _self.logger.warning(
                    f"âš ï¸ Mismatch labels: rows_only={len(missing_in_cols)}, cols_only={len(missing_in_idx)}"
                )
                # Intersection pour carrÃ© cohÃ©rent
                common = sorted(idx_set & col_set)
                cooc_matrix = cooc_matrix.loc[common, common]
                _self.logger.info(
                    f"ğŸ”§ Matrice rÃ©duite Ã  intersection commune: {cooc_matrix.shape}"
                )

            # Forcer colonnes = index si ordre diffÃ©rent
            if not (cooc_matrix.index.tolist() == cooc_matrix.columns.tolist()):
                _self.logger.warning("âš ï¸ RÃ©ordonnancement des colonnes pour correspondre Ã  l'index")
                cooc_matrix = cooc_matrix[cooc_matrix.index]

            # VÃ©rifier doublons
            if cooc_matrix.index.has_duplicates or cooc_matrix.columns.has_duplicates:
                _self.logger.warning("âš ï¸ Doublons dÃ©tectÃ©s dans labels; dÃ©duplication")
                # DÃ©duplication par agrÃ©gation (somme)
                cooc_matrix = (
                    cooc_matrix.groupby(cooc_matrix.index).sum()
                )
                cooc_matrix = cooc_matrix[cooc_matrix.index]  # rÃ©aligner colonnes
                _self.logger.info(
                    f"ğŸ” AprÃ¨s dÃ©duplication: {cooc_matrix.shape}"
                )

            _self.logger.info(
                f"âœ… Matrice finalisÃ©e: {cooc_matrix.shape} | Sample: {cooc_matrix.index[:5].tolist()}"
            )

            if not _self.ingredients_list_path.exists():
                st.error(f"âŒ Liste des ingrÃ©dients introuvable: {_self.ingredients_list_path}")
                st.stop()
                return None

            ingredients_list = pd.read_csv(_self.ingredients_list_path)
            ingredients_list['ingredient'] = ingredients_list['ingredient'].str.strip()
            _self.logger.info(
                f"âœ… Liste chargÃ©e: {len(ingredients_list)} ingrÃ©dients | Top 5: {ingredients_list.head()['ingredient'].tolist()}"
            )

            return cooc_matrix, ingredients_list

        except Exception as e:
            st.error(f"âŒ Erreur de chargement: {e}")
            _self.logger.error(f"Failed to load precomputed matrix: {e}")
            st.stop()
            return None

    def render_sidebar(self) -> dict[str, int | bool]:
        """Affiche la sidebar avec les paramÃ¨tres de clustering.

        Returns:
            Dictionnaire contenant les paramÃ¨tres sÃ©lectionnÃ©s.
        """
        st.sidebar.header("ğŸ”§ ParamÃ¨tres de Clustering")

        st.sidebar.info("ğŸ“Š Matrice prÃ©calculÃ©e: 300 ingrÃ©dients")

        # Nombre d'ingrÃ©dients Ã  sÃ©lectionner
        n_ingredients = st.sidebar.slider(
            "Nombre d'ingrÃ©dients Ã  analyser",
            min_value=40,
            max_value=300,
            value=40,
            step=10,
            help="SÃ©lectionner les N ingrÃ©dients les plus frÃ©quents depuis la matrice 300x300",
        )

        # Nombre de clusters
        n_clusters = st.sidebar.slider(
            "Nombre de clusters",
            min_value=3,
            max_value=20,
            value=4,
            step=1,
            help="Nombre de groupes d'ingrÃ©dients Ã  crÃ©er avec K-means",
        )

        # ParamÃ¨tres t-SNE
        st.sidebar.subheader("ğŸ¨ Visualisation t-SNE")
        tsne_perplexity = st.sidebar.slider(
            "PerplexitÃ©",
            min_value=5,
            max_value=50,
            value=30,
            step=5,
            help="ContrÃ´le la densitÃ© des groupes (5=local, 50=global)",
        )

        # Bouton d'analyse
        analyze_button = st.sidebar.button("ğŸš€ Lancer l'analyse", type="primary")

        return {
            "n_ingredients": n_ingredients,
            "n_clusters": n_clusters,
            "tsne_perplexity": tsne_perplexity,
            "analyze_button": analyze_button,
        }

    def _select_top_ingredients(
        self, cooc_matrix: pd.DataFrame, ingredients_list: pd.DataFrame, n: int
    ) -> tuple[pd.DataFrame, list[str]]:
        """SÃ©lectionne robustement les N ingrÃ©dients les plus frÃ©quents.

        Diagnostic dÃ©taillÃ©:
        - Taille liste vs matrice
        - Intersections
        - Fallback si mismatch complet (utilisation directe de l'index matrice)
        """
        matrix_index = list(cooc_matrix.index)
        matrix_cols = list(cooc_matrix.columns)

        # Logs de diagnostic
        self.logger.info(
            f"ğŸ” Diagnostic sÃ©lection: matrix_index={len(matrix_index)}, matrix_cols={len(matrix_cols)}, list_rows={len(ingredients_list)}"
        )

        if set(matrix_index) != set(matrix_cols):
            self.logger.warning("âš ï¸ Les labels lignes/colonnes ne correspondent pas parfaitement.")

        list_ings = ingredients_list['ingredient'].tolist()
        inter_with_index = set(list_ings) & set(matrix_index)
        inter_with_cols = set(list_ings) & set(matrix_cols)
        self.logger.info(
            f"ğŸ” Intersections: with_index={len(inter_with_index)}, with_cols={len(inter_with_cols)}"
        )

        if not inter_with_index:
            self.logger.error("âŒ Aucune intersection entre la liste et l'index de la matrice. Fallback sur index brut.")
            # Fallback: prendre directement premiers n ingrÃ©dients de la matrice
            top_final = matrix_index[:n]
            sub_matrix = cooc_matrix.loc[top_final, top_final]
            self.logger.info(
                f"âœ… Fallback utilisÃ©: {len(top_final)} ingrÃ©dients | shape={sub_matrix.shape}"
            )
            return sub_matrix, top_final

        # Filtrage selon index (pas colonnes encore)
        filtered = ingredients_list[ingredients_list['ingredient'].isin(matrix_index)]
        top = filtered.nlargest(n, 'frequency')['ingredient'].tolist()

        # VÃ©rification colonnes
        top_valid = [ing for ing in top if ing in set(matrix_cols)]
        lost = set(top) - set(top_valid)
        if lost:
            self.logger.warning(
                f"âš ï¸ IngrÃ©dients prÃ©sents dans index mais absents des colonnes ignorÃ©s: {list(lost)[:8]}{'...' if len(lost)>8 else ''}"
            )

        top_final = top_valid[:n]
        if len(top_final) < n:
            self.logger.warning(
                f"âš ï¸ Seulement {len(top_final)}/{n} ingrÃ©dients disponibles aprÃ¨s filtrage"
            )

        sub_matrix = cooc_matrix.reindex(index=top_final, columns=top_final)
        if sub_matrix.isna().any().any():
            self.logger.warning("âš ï¸ NaN dÃ©tectÃ©s dans sous-matrice; remplissage Ã  0")
            sub_matrix = sub_matrix.fillna(0)

        self.logger.info(
            f"âœ… SÃ©lection finale: {len(top_final)} ingrÃ©dients | shape={sub_matrix.shape}"
        )
        return sub_matrix, top_final

    def _perform_clustering(self, matrix: pd.DataFrame, n_clusters: int) -> np.ndarray:
        """Effectue le clustering K-means sur la matrice.

        Args:
            matrix: Matrice de co-occurrence.
            n_clusters: Nombre de clusters.

        Returns:
            Array des labels de cluster.
        """
        self.logger.info(f"Performing K-means clustering with k={n_clusters}")

        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(matrix.values)

        self.logger.info(f"Clustering completed: {len(set(clusters))} unique clusters")

        return clusters

    def _generate_tsne(
        self, matrix: pd.DataFrame, clusters: np.ndarray, perplexity: int
    ) -> dict:
        """GÃ©nÃ¨re la visualisation t-SNE.

        Args:
            matrix: Matrice de co-occurrence.
            clusters: Labels de cluster.
            perplexity: ParamÃ¨tre de perplexitÃ©.

        Returns:
            Dict avec coordonnÃ©es x, y et mÃ©tadonnÃ©es.
        """
        self.logger.info(f"Generating t-SNE visualization with perplexity={perplexity}")

        try:
            # Ajuster la perplexitÃ© si nÃ©cessaire
            n_samples = matrix.shape[0]
            adjusted_perplexity = min(perplexity, n_samples - 1)

            if adjusted_perplexity != perplexity:
                self.logger.warning(
                    f"Perplexity adjusted from {perplexity} to {adjusted_perplexity} (n_samples={n_samples})"
                )

            # t-SNE
            tsne = TSNE(
                n_components=2,
                perplexity=adjusted_perplexity,
                random_state=42,
                max_iter=1000,
            )

            coords = tsne.fit_transform(matrix.values)

            return {
                "x_coords": coords[:, 0].tolist(),
                "y_coords": coords[:, 1].tolist(),
                "ingredient_names": matrix.index.tolist(),
                "cluster_labels": clusters.tolist(),
                "n_clusters": len(set(clusters)),
                "tsne_params": {
                    "perplexity": adjusted_perplexity,
                    "max_iter": 1000,
                    "random_state": 42,
                    "method": "tsne",
                },
            }

        except Exception as e:
            self.logger.error(f"t-SNE failed: {e}")
            return {"error": str(e)}

    def render_cooccurrence_analysis(
        self, ingredient_names: list[str], matrix: pd.DataFrame
    ) -> None:
        """Affiche l'analyse de co-occurrence interactive."""
        st.subheader("ğŸ” Analyse de Co-occurrence")

        col1, col2 = st.columns(2)

        with col1:
            ing1 = st.selectbox("Premier ingrÃ©dient", options=ingredient_names, index=0)

        with col2:
            ing2 = st.selectbox(
                "DeuxiÃ¨me ingrÃ©dient",
                options=ingredient_names,
                index=1 if len(ingredient_names) > 1 else 0,
            )

        if ing1 and ing2 and ing1 != ing2:
            try:
                score = matrix.at[ing1, ing2]
                max_score = matrix.values.max()
                avg_score = matrix.values[matrix.values > 0].mean()

                col_m1, col_m2, col_m3 = st.columns(3)

                with col_m1:
                    st.metric("Score", f"{score:.0f}", help="Nombre de recettes communes")

                with col_m2:
                    percentile = (score / max_score) * 100 if max_score > 0 else 0
                    st.metric("Percentile", f"{percentile:.1f}%")

                with col_m3:
                    ratio = score / avg_score if avg_score > 0 else 0
                    st.metric("vs Moyenne", f"{ratio:.1f}x")

                # Barre de progression
                if max_score > 0:
                    st.progress(score / max_score)

                # InterprÃ©tation
                if score >= avg_score * 2:
                    st.success("ğŸ”¥ Combinaison trÃ¨s frÃ©quente!")
                elif score >= avg_score:
                    st.info("âœ… Combinaison courante")
                elif score > 0:
                    st.warning("âš ï¸ Combinaison rare")
                else:
                    st.error("âŒ Aucune co-occurrence")

            except Exception as e:
                st.warning(f"Erreur: {e}")

    def render_clusters(
        self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int
    ) -> None:
        """Affiche les clusters d'ingrÃ©dients."""
        st.subheader("ğŸ¯ Clusters d'IngrÃ©dients")

        colors = ["ğŸ”´", "ğŸŸ ", "ğŸŸ¡", "ğŸŸ¢", "ğŸ”µ", "ğŸŸ£", "âš«", "âšª", "ğŸŸ¤", "ğŸ”˜"]

        for cluster_id in range(n_clusters):
            cluster_ings = [
                ingredient_names[i]
                for i, c in enumerate(clusters)
                if c == cluster_id
            ]

            color = colors[cluster_id % len(colors)]

            with st.expander(
                f"{color} Cluster {cluster_id + 1} ({len(cluster_ings)} ingrÃ©dients)",
                expanded=cluster_id < 2,  # Expand first 2 clusters only
            ):
                cols = st.columns(4)
                for i, ing in enumerate(cluster_ings):
                    cols[i % 4].write(f"â€¢ **{ing}**")

    def render_tsne_visualization(self, tsne_data: dict) -> None:
        """Affiche la visualisation t-SNE."""
        st.subheader("ğŸ¨ Visualisation t-SNE 2D")

        if "error" in tsne_data:
            st.error(f"âŒ Erreur t-SNE: {tsne_data['error']}")
            return

        # CrÃ©er le graphique
        fig = go.Figure()

        colors = [
            "#FF6B6B",
            "#4ECDC4",
            "#45B7D1",
            "#96CEB4",
            "#FFEAA7",
            "#DDA0DD",
            "#98D8C8",
            "#F7DC6F",
            "#BB8FCE",
            "#85C1E9",
            "#F8B88B",
            "#FAA0A0",
            "#B0E57C",
            "#87CEEB",
            "#DDA0DD",
            "#F0E68C",
            "#FFB6C1",
            "#20B2AA",
            "#FF69B4",
            "#BA55D3",
        ]

        n_clusters = tsne_data["n_clusters"]

        for cluster_id in range(n_clusters):
            mask = [label == cluster_id for label in tsne_data["cluster_labels"]]
            cluster_x = [x for i, x in enumerate(tsne_data["x_coords"]) if mask[i]]
            cluster_y = [y for i, y in enumerate(tsne_data["y_coords"]) if mask[i]]
            cluster_names = [
                name for i, name in enumerate(tsne_data["ingredient_names"]) if mask[i]
            ]

            color = colors[cluster_id % len(colors)]

            fig.add_trace(
                go.Scatter(
                    x=cluster_x,
                    y=cluster_y,
                    mode="markers+text",
                    marker=dict(size=12, color=color, line=dict(width=2, color="white"), opacity=0.8),
                    text=cluster_names,
                    textposition="top center",
                    textfont=dict(size=10),
                    name=f"Cluster {cluster_id + 1}",
                    hovertemplate=f"<b>%{{text}}</b><br>Cluster: {cluster_id + 1}<extra></extra>",
                )
            )

        fig.update_layout(
            title="Visualisation t-SNE des IngrÃ©dients",
            xaxis_title="Dimension 1",
            yaxis_title="Dimension 2",
            showlegend=True,
            height=600,
            hovermode="closest",
            plot_bgcolor="rgba(245,245,245,0.8)",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        )

        st.plotly_chart(fig, use_container_width=True)

        with st.expander("â„¹ï¸ Ã€ propos de t-SNE"):
            st.markdown(
                """
            **t-SNE** rÃ©duit la dimensionnalitÃ© pour visualiser les similaritÃ©s entre ingrÃ©dients.
            
            - **Points proches** = ingrÃ©dients avec profils de co-occurrence similaires
            - **Couleurs** = clusters K-means
            - **Distance** = mesure de similaritÃ© culinaire
            
            **ParamÃ¨tres utilisÃ©s**:
            - PerplexitÃ©: {}
            - ItÃ©rations: 1000
            - Seed: 42
            """.format(
                    tsne_data["tsne_params"]["perplexity"]
                )
            )

    def render_sidebar_statistics(
        self, clusters: np.ndarray, ingredient_names: list[str]
    ) -> None:
        """Affiche les statistiques dans la sidebar."""
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ“Š Statistiques")

        cluster_counts = pd.Series(clusters).value_counts().sort_index()

        st.sidebar.metric("IngrÃ©dients analysÃ©s", len(ingredient_names))
        st.sidebar.metric("Clusters crÃ©Ã©s", len(cluster_counts))

        # Graphique
        st.sidebar.markdown("**RÃ©partition:**")

        colors = [
            "#FF6B6B",
            "#4ECDC4",
            "#45B7D1",
            "#96CEB4",
            "#FFEAA7",
            "#DDA0DD",
            "#98D8C8",
            "#F7DC6F",
            "#BB8FCE",
            "#85C1E9",
        ]

        fig = go.Figure()

        for i, count in enumerate(cluster_counts):
            percentage = (count / len(ingredient_names)) * 100
            color = colors[i % len(colors)]

            fig.add_trace(
                go.Bar(
                    x=[count],
                    y=[f"C{i + 1}"],
                    orientation="h",
                    marker_color=color,
                    text=f"{count} ({percentage:.0f}%)",
                    textposition="outside",
                    showlegend=False,
                )
            )

        fig.update_layout(
            xaxis_title="Nombre",
            height=min(400, len(cluster_counts) * 40 + 100),
            margin=dict(l=10, r=10, t=10, b=10),
            font=dict(size=10),
        )

        st.sidebar.plotly_chart(fig, use_container_width=True)

    def _render_step_1_preprocessing(self) -> None:
        """Affiche l'Ã©tape 1 : PrÃ©traitement NLP des ingrÃ©dients."""
        st.markdown("---")
        st.header("ğŸ“ˆ Ã‰TAPE 1 : PrÃ©traitement NLP des ingrÃ©dients")

        st.markdown(
            """
        **Question :** Comment normaliser et regrouper les variantes d'un mÃªme ingrÃ©dient ?

        Les recettes utilisent des descriptions variÃ©es pour un mÃªme ingrÃ©dient (ex: "sel", "gros sel",
        "sel de mer", "sel fin"). Le prÃ©traitement NLP vise Ã  identifier et regrouper ces variantes
        pour crÃ©er une reprÃ©sentation cohÃ©rente.

        **MÃ©trique :** Taux de rÃ©duction du nombre d'ingrÃ©dients uniques aprÃ¨s normalisation.
        
        **ğŸ’¡ Note technique :** Cette Ã©tape a Ã©tÃ© **prÃ©calculÃ©e Ã  froid** lors de la gÃ©nÃ©ration de la 
        matrice 300Ã—300 avec `utils/preprocess_ingredients_matrix.py`. Environ **~230,000 recettes** ont 
        Ã©tÃ© traitÃ©es pour extraire et normaliser les 300 ingrÃ©dients les plus frÃ©quents.

        **MÃ©thodologie appliquÃ©e :**
        - Normalisation : minuscules, suppression ponctuation, filtrage stop words
        - Regroupement : variantes lexicales fusionnÃ©es
        - RÃ©duction typique : ~70% des variantes Ã©liminÃ©es

        **ğŸ¯ RÃ©sultat :** Le prÃ©traitement rÃ©duit significativement la redondance en identifiant
        les variantes linguistiques d'un mÃªme ingrÃ©dient. Cette Ã©tape est cruciale pour obtenir une
        matrice de co-occurrence fiable et permet de concentrer l'analyse sur les vÃ©ritables patterns
        culinaires plutÃ´t que sur les variations de nomenclature.
        """
        )

    def _render_step_2_cooccurrence(
        self, ingredient_names: list[str], matrix: pd.DataFrame
    ) -> None:
        """Affiche l'Ã©tape 2 : CrÃ©ation de la matrice de co-occurrence."""
        st.markdown("---")
        st.header("ğŸ“ˆ Ã‰TAPE 2 : Matrice de co-occurrence")

        st.markdown(
            """
        **Objectif :** Quantifier la frÃ©quence d'apparition conjointe de chaque paire d'ingrÃ©dients.

        La matrice de co-occurrence capture l'information fondamentale : combien de fois deux
        ingrÃ©dients apparaissent ensemble dans les recettes. Cette matrice symÃ©trique constitue
        la base de notre analyse de similaritÃ©.

        **MÃ©thode :** Pour chaque recette, toutes les paires d'ingrÃ©dients prÃ©sents sont comptabilisÃ©es.
        
        **ğŸ’¡ Note technique :** Cette matrice **300Ã—300** a Ã©tÃ© **prÃ©calculÃ©e Ã  froid** sur l'ensemble 
        du corpus (~230,000 recettes). Vous sÃ©lectionnez dynamiquement un sous-ensemble (40-300 ingrÃ©dients) 
        de cette matrice pour votre analyse.
        """
        )

        # Statistiques de la matrice
        total_cooccurrences = int(matrix.values.sum() / 2)
        non_zero_pairs = int((matrix.values > 0).sum() / 2)
        matrix_size = len(ingredient_names)
        max_possible_pairs = matrix_size * (matrix_size - 1) / 2
        sparsity = (1 - non_zero_pairs / max_possible_pairs) * 100

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Dimension matrice", f"{matrix_size}Ã—{matrix_size}")
        with col2:
            st.metric("Co-occurrences totales", f"{total_cooccurrences:,}")
        with col3:
            st.metric("Paires non-nulles", f"{non_zero_pairs:,}")
        with col4:
            st.metric(
                "SparsitÃ©",
                f"{sparsity:.1f}%",
                help="Pourcentage de paires sans co-occurrence",
            )

        st.markdown("---")

        # Analyse interactive de co-occurrence
        self.render_cooccurrence_analysis(ingredient_names, matrix)

        st.markdown(
            """
        **ğŸ“Š Ce que rÃ©vÃ¨le la matrice :**

        La distribution des co-occurrences n'est pas uniforme. Certaines paires d'ingrÃ©dients
        apparaissent ensemble dans des milliers de recettes, rÃ©vÃ©lant des associations culinaires
        fortes.

        """
        )

    def _render_step_3_clustering(
        self, clusters: np.ndarray, ingredient_names: list[str], n_clusters: int
    ) -> None:
        """Affiche l'Ã©tape 3 : Clustering K-means."""
        st.markdown("---")
        st.header("ğŸ“ˆ Ã‰TAPE 3 : Clustering K-means")

        st.markdown(
            f"""
        **Objectif :** Regrouper automatiquement les ingrÃ©dients en {n_clusters} familles distinctes.

        L'algorithme K-means partitionne les ingrÃ©dients en fonction de leurs profils de co-occurrence.
        Deux ingrÃ©dients dans le mÃªme cluster partagent des contextes d'utilisation similaires, mÃªme
        s'ils ne co-occurrent pas directement.

        **MÃ©thode :** K-means avec k={n_clusters}, distance euclidienne sur les vecteurs de co-occurrence.
        """
        )

        # Statistiques des clusters
        cluster_counts = pd.Series(clusters).value_counts().sort_index()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nombre de clusters", n_clusters)
        with col2:
            avg_size = len(ingredient_names) / n_clusters
            st.metric("Taille moyenne", f"{avg_size:.1f} ingrÃ©dients")
        with col3:
            largest_cluster_size = cluster_counts.max()
            st.metric("Plus grand cluster", f"{largest_cluster_size} ingrÃ©dients")

        st.markdown("---")

        # Affichage des clusters
        self.render_clusters(clusters, ingredient_names, n_clusters)

        st.markdown(
            f"""
        **ğŸ¯ InterprÃ©tation des clusters :**

        Les clusters arrivent Ã  rÃ©vÃ©ler des "famille culinaire" d'ingrÃ©dients. Ils peuvent Ãªtre :
        - **IngrÃ©dients pour patisserie**
        - **Produits de recettes salÃ©s**

        **Limite mÃ©thodologique** : Le choix de k={n_clusters} est paramÃ©trique. DiffÃ©rentes valeurs
        de k rÃ©vÃ¨lent des structures Ã  diffÃ©rentes granularitÃ©s.
        De plus, les clusters ont tendance Ã  ne pas Ãªtre de la mÃªme taille car une masse d'ingrÃ©dient Ã  faible co-occurence se regrouppent ensemble.
        """
        )

    def _render_step_4_visualization(self, tsne_data: dict) -> None:
        """Affiche l'Ã©tape 4 : Visualisation t-SNE 2D."""
        st.markdown("---")
        st.header("ğŸ“ˆ Ã‰TAPE 4 : Visualisation t-SNE 2D")

        st.markdown(
            """
        **Objectif :** Projeter l'espace haute-dimensionnalitÃ© des co-occurrences en 2D pour exploration visuelle.

        La matrice de co-occurrence est un espace Ã  n dimensions (une par ingrÃ©dient). t-SNE
        (t-Distributed Stochastic Neighbor Embedding) rÃ©duit cette dimensionnalitÃ© Ã  2D tout en
        prÃ©servant les proximitÃ©s locales.

        **MÃ©thode :** t-SNE avec perplexitÃ© ajustÃ©e, optimisation par descente de gradient.
        """
        )

        # Visualisation t-SNE
        self.render_tsne_visualization(tsne_data)

        st.markdown(
            """
        **ğŸ” Lecture de la visualisation :**

        - **ProximitÃ© spatiale** : Les ingrÃ©dients proches dans l'espace 2D ont des profils de
          co-occurrence similaires (utilisÃ©s dans des contextes culinaires similaires)
        - **Couleurs** : Chaque couleur reprÃ©sente un cluster K-means. La cohÃ©sion spatiale des
          couleurs valide la qualitÃ© du clustering
        - **Groupes isolÃ©s** : Les clusters bien sÃ©parÃ©s gÃ©ographiquement indiquent des familles
          culinaires distinctes

        **ğŸ’¡ Insights visuels :**

        La visualisation rÃ©vÃ¨le souvent une structure non-linÃ©aire de l'espace culinaire. Certains
        ingrÃ©dients "pont" peuvent se situer entre plusieurs clusters, reflÃ©tant leur polyvalence
        (ex: l'huile d'olive utilisÃ©e dans de multiples contextes, ou l'eau).

        **Validation du clustering** : Si les couleurs (clusters K-means) forment des groupes
        visuellement cohÃ©rents dans l'espace t-SNE, cela confirme que le clustering a capturÃ©
        des structures rÃ©elles plutÃ´t qu'artificielles.

        **Limite de t-SNE** : La reprÃ©sentation 2D est approximative. Les distances absolues ne
        sont pas strictement prÃ©servÃ©es, seules les proximitÃ©s relatives comptent. DiffÃ©rentes
        exÃ©cutions peuvent donner des configurations lÃ©gÃ¨rement diffÃ©rentes (non-dÃ©terminisme).
        """
        )

    def _render_conclusion(
        self, ingredient_names: list[str], clusters: np.ndarray, n_clusters: int
    ) -> None:
        """Affiche la conclusion de l'analyse."""
        st.markdown("---")
        st.subheader("ğŸ“‹ Conclusion de l'analyse")

        # Calculer quelques statistiques finales
        cluster_counts = pd.Series(clusters).value_counts()
        largest_cluster = cluster_counts.max()
        smallest_cluster = cluster_counts.min()

        st.markdown(
            f"""
        ### SynthÃ¨se des rÃ©sultats

        **1. PrÃ©traitement NLP rÃ©ussi :** La normalisation automatique a permis de rÃ©duire
        significativement la redondance des variantes d'ingrÃ©dients, crÃ©ant une base solide
        pour l'analyse.

        **2. Structure rÃ©vÃ©lÃ©e par la co-occurrence :** L'analyse de {len(ingredient_names)}
        ingrÃ©dients a rÃ©vÃ©lÃ© des patterns clairs d'association culinaire, confirmant que la
        cuisine n'est pas alÃ©atoire.

        **3. Clustering cohÃ©rent :** L'algorithme K-means a identifiÃ© {n_clusters} familles
        d'ingrÃ©dients distinctes, avec des tailles variant de {smallest_cluster} Ã  {largest_cluster}
        ingrÃ©dients. Ces clusters essaye de capturer des insight sur le co-usage des ingrÃ©dients.

        **4. Validation visuelle :** La projection t-SNE montre la structure des clusters et
        l'organisation de l'espace culinaire.

        ### Applications pratiques

        Ces rÃ©sultats peuvent Ãªtre utilisÃ©s pour :
        - **SystÃ¨mes de recommandation** : SuggÃ©rer des ingrÃ©dients complÃ©mentaires lors de la
          crÃ©ation de recettes
        - **Analyse nutritionnelle** : Identifier les associations alimentaires courantes pour
          des Ã©tudes diÃ©tÃ©tiques, nottament en reliant les informations caloriques
        - **CrÃ©ativitÃ© culinaire** : DÃ©couvrir des combinaisons innovantes en explorant les
          frontiÃ¨res entre clusters
        - **DÃ©tection d'anomalies** : Identifier des recettes avec des combinaisons inhabituelles

        ### Limites et perspectives

        **Limites :**
        - La co-occurrence ne capture pas l'ordre ou les quantitÃ©s des ingrÃ©dients
        - Les ingrÃ©dients trÃ¨s rares ne sont pas reprÃ©sentÃ©s et ceux trop prÃ©sent
        peuvent Ãªtre mal reprÃ©sentÃ©s

        **Perspectives d'amÃ©lioration :**
        - Clustering hiÃ©rarchique pour rÃ©vÃ©ler plusieurs niveaux de granularitÃ©
        - IntÃ©gration d'informations sÃ©mantiques (catÃ©gories nutritionnelles, origines)
        - ModÃ¨les de recommandation basÃ©s sur les embeddings d'ingrÃ©dients
        """
        )

    def run(self) -> None:
        """Point d'entrÃ©e principal de la page."""
        self.logger.info("Starting ingredients clustering analysis with precomputed matrix")

        # Introduction et User Story
        with st.expander("ğŸ¯ Objectifs et mÃ©thodologie de l'analyse", expanded=True):
            st.markdown(
                """
            ### Peut-on regrouper les ingrÃ©dients selon leurs usages culinaires ?

            Cette analyse explore les patterns de co-occurrence d'ingrÃ©dients dans les recettes pour
            identifier les associations culinaires naturelles. En analysant des milliers de recettes,
            nous rÃ©vÃ©lons les combinaisons d'ingrÃ©dients qui apparaissent frÃ©quemment ensemble.

            **Questions centrales :** Quels ingrÃ©dients sont naturellement associÃ©s ? Existe-t-il des
            familles d'ingrÃ©dients distinctes ? Comment les ingrÃ©dients se regroupent-ils en fonction
            de leurs profils d'utilisation ?

            **Approche :** 
            - **Ã‰tapes 1-2 (prÃ©calculÃ©es Ã  froid)** : Analyse NLP des listes d'ingrÃ©dients et construction 
              d'une matrice de co-occurrence 300Ã—300
            - **Ã‰tapes 3-4 (temps rÃ©el)** : Clustering automatique par K-means et visualisation en 2D par t-SNE

            **ProblÃ©matique :** Dans un espace culinaire oÃ¹ des milliers d'ingrÃ©dients peuvent Ãªtre
            combinÃ©s, comment identifier automatiquement les groupes d'ingrÃ©dients qui partagent des
            contextes d'utilisation similaires ?
            
            **ğŸ’¡ Optimisation** : Les Ã©tapes 1-2 sont prÃ©calculÃ©es pour accÃ©lÃ©rer l'analyse. Vous ajustez 
            le nombre d'ingrÃ©dients (40-300) et de clusters (3-20) en temps rÃ©el.
            """
            )

        # Sidebar
        params = self.render_sidebar()
        self.logger.debug(f"Parameters: {params}")

        # Charger la matrice prÃ©calculÃ©e
        data = self._load_cooccurrence_matrix()

        if data is None:
            return

        full_matrix, ingredients_list = data

        # VÃ©rifier si les paramÃ¨tres ont changÃ©
        params_changed = False
        if "last_params" in st.session_state:
            last = st.session_state["last_params"]
            if (
                last["n_ingredients"] != params["n_ingredients"]
                or last["n_clusters"] != params["n_clusters"]
                or last["tsne_perplexity"] != params["tsne_perplexity"]
            ):
                params_changed = True

        # DÃ©cider si on lance l'analyse
        should_analyze = (
            params["analyze_button"]
            or "clusters" not in st.session_state
            or params_changed
        )

        if should_analyze:
            self.logger.info(
                f"Running analysis: n_ingredients={params['n_ingredients']}, n_clusters={params['n_clusters']}"
            )

            with st.spinner("Analyse en cours..."):
                # SÃ©lectionner les top N ingrÃ©dients
                matrix, ingredient_names = self._select_top_ingredients(
                    full_matrix, ingredients_list, params["n_ingredients"]
                )

                # Clustering
                clusters = self._perform_clustering(matrix, params["n_clusters"])

                # t-SNE
                tsne_data = self._generate_tsne(matrix, clusters, params["tsne_perplexity"])

                # Sauvegarder dans session
                st.session_state["matrix"] = matrix
                st.session_state["ingredient_names"] = ingredient_names
                st.session_state["clusters"] = clusters
                st.session_state["tsne_data"] = tsne_data
                st.session_state["last_params"] = params.copy()

        # Afficher les rÃ©sultats si disponibles
        if "clusters" in st.session_state:
            matrix = st.session_state["matrix"]
            ingredient_names = st.session_state["ingredient_names"]
            clusters = st.session_state["clusters"]
            tsne_data = st.session_state["tsne_data"]

            # MÃ©triques
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ“Š Matrice source", "300x300")
            with col2:
                st.metric("ğŸ¥˜ IngrÃ©dients analysÃ©s", f"{len(ingredient_names)}")
            with col3:
                st.metric("ğŸ¯ Clusters crÃ©Ã©s", f"{params['n_clusters']}")

            # Ã‰TAPES
            self._render_step_1_preprocessing()
            self._render_step_2_cooccurrence(ingredient_names, matrix)
            self._render_step_3_clustering(clusters, ingredient_names, params["n_clusters"])
            self._render_step_4_visualization(tsne_data)
            self._render_conclusion(ingredient_names, clusters, params["n_clusters"])

            # Statistiques sidebar
            self.render_sidebar_statistics(clusters, ingredient_names)

        # Footer
        st.markdown("---")
        st.caption(
            "ğŸ’¡ **Configuration** : Ajustez les paramÃ¨tres dans la sidebar pour explorer diffÃ©rentes configurations."
        )
